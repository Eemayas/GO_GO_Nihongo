{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "# %pip install datasets\n",
    "# %pip install janome mojimoji\n",
    "# %pip install transformers\n",
    "# %pip install sentencepiece\n",
    "# %pip install tensorflow\n",
    "# clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "私 は 日本語 の ﾃｷｽﾄ を 翻訳 し ます ｡\n"
     ]
    }
   ],
   "source": [
    "from janome.tokenizer import Tokenizer\n",
    "import mojimoji\n",
    "\n",
    "# Initialize Japanese tokenizer\n",
    "tokenizer = Tokenizer()\n",
    "\n",
    "\n",
    "def preprocess_japanese_text(text):\n",
    "    # Convert full-width characters to half-width\n",
    "    text = mojimoji.zen_to_han(text)\n",
    "\n",
    "    # Tokenize the text\n",
    "    tokens = tokenizer.tokenize(text, wakati=True)\n",
    "\n",
    "    # Join tokens with a space to preserve word boundaries for translation models\n",
    "    preprocessed_text = \" \".join(tokens)\n",
    "\n",
    "    # Remove any unnecessary whitespace\n",
    "    preprocessed_text = preprocessed_text.strip()\n",
    "\n",
    "    return preprocessed_text\n",
    "\n",
    "\n",
    "# Example usage\n",
    "text = \"私は日本語のテキストを翻訳します。\"\n",
    "processed_text = preprocess_japanese_text(text)\n",
    "print(processed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\n",
    "    \"hf://datasets/Verah/tatoeba_dedupe_en-jp_2024-March-01/tatoeba_dedupe_random_en-jp_2024-03-01.tsv.gz\",\n",
    "    sep=\"\\t\",\n",
    ")\n",
    "df.to_csv(\"./datas/eng_jap_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>english</th>\n",
       "      <th>japanese</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>While in England I often consulted the guidebook.</td>\n",
       "      <td>イギリスにいる間、私はよくそのガイドブックを参考にした。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Look at the sports car over there.</td>\n",
       "      <td>あそこのスポーツカーを見なさい。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Never did I expect that he would fail the exam...</td>\n",
       "      <td>彼が試験に失敗するなんて私は予想もしなかった。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>He knows no foreign language except English.</td>\n",
       "      <td>彼は英語以外の外国語は全く知らない。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>All their secrets have been revealed.</td>\n",
       "      <td>彼らの秘密が全部暴かれた。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>He promised to return the money without fail.</td>\n",
       "      <td>彼は間違いなく金を返すと約束した。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>To tell the truth, things at home haven't been...</td>\n",
       "      <td>実は家庭が上手くいってなくてさ・・・。離婚しようかと思ってるんだ。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Can I have your phone number?</td>\n",
       "      <td>電話番号教えてもらってもいい？</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Even a monkey can solve a problem as simple as...</td>\n",
       "      <td>こんなに簡単な問題は猿さえも解けますよ。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>You had better speak more naturally.</td>\n",
       "      <td>君はもっと自然に話す方がよい。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Foreign investors withdrew their money from Am...</td>\n",
       "      <td>外国人投資家は資金をアメリカから引き揚げた。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Do you study English?</td>\n",
       "      <td>君は英語を勉強しますか。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>His persistent efforts resulted in failure.</td>\n",
       "      <td>彼の懸命の努力は失敗に終わった。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>This dress comes in three sizes.</td>\n",
       "      <td>このドレスには３つのサイズがあります。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>When will Mother come home?</td>\n",
       "      <td>母はいつ帰宅するのでしょうか。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Long dresses have come in fashion this year.</td>\n",
       "      <td>今年はロングドレスが流行している。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Have you ever been to Boston?</td>\n",
       "      <td>ボストン行ったことある？</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>He is equal to the task.</td>\n",
       "      <td>彼はその仕事をやる能力がある。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>Ignore her.</td>\n",
       "      <td>シカトしろ。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>We eat a fresh, green salad every day.</td>\n",
       "      <td>毎日新鮮な野菜サラダを食べてます。</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                                            english  \\\n",
       "0    1  While in England I often consulted the guidebook.   \n",
       "1    2                 Look at the sports car over there.   \n",
       "2    3  Never did I expect that he would fail the exam...   \n",
       "3    4       He knows no foreign language except English.   \n",
       "4    5              All their secrets have been revealed.   \n",
       "5    6      He promised to return the money without fail.   \n",
       "6    7  To tell the truth, things at home haven't been...   \n",
       "7    8                      Can I have your phone number?   \n",
       "8    9  Even a monkey can solve a problem as simple as...   \n",
       "9   10               You had better speak more naturally.   \n",
       "10  11  Foreign investors withdrew their money from Am...   \n",
       "11  12                              Do you study English?   \n",
       "12  13        His persistent efforts resulted in failure.   \n",
       "13  14                   This dress comes in three sizes.   \n",
       "14  15                        When will Mother come home?   \n",
       "15  16       Long dresses have come in fashion this year.   \n",
       "16  17                      Have you ever been to Boston?   \n",
       "17  18                           He is equal to the task.   \n",
       "18  19                                        Ignore her.   \n",
       "19  20             We eat a fresh, green salad every day.   \n",
       "\n",
       "                             japanese  \n",
       "0        イギリスにいる間、私はよくそのガイドブックを参考にした。  \n",
       "1                    あそこのスポーツカーを見なさい。  \n",
       "2             彼が試験に失敗するなんて私は予想もしなかった。  \n",
       "3                  彼は英語以外の外国語は全く知らない。  \n",
       "4                       彼らの秘密が全部暴かれた。  \n",
       "5                   彼は間違いなく金を返すと約束した。  \n",
       "6   実は家庭が上手くいってなくてさ・・・。離婚しようかと思ってるんだ。  \n",
       "7                     電話番号教えてもらってもいい？  \n",
       "8                こんなに簡単な問題は猿さえも解けますよ。  \n",
       "9                     君はもっと自然に話す方がよい。  \n",
       "10             外国人投資家は資金をアメリカから引き揚げた。  \n",
       "11                       君は英語を勉強しますか。  \n",
       "12                   彼の懸命の努力は失敗に終わった。  \n",
       "13                このドレスには３つのサイズがあります。  \n",
       "14                    母はいつ帰宅するのでしょうか。  \n",
       "15                  今年はロングドレスが流行している。  \n",
       "16                       ボストン行ったことある？  \n",
       "17                    彼はその仕事をやる能力がある。  \n",
       "18                             シカトしろ。  \n",
       "19                  毎日新鮮な野菜サラダを食べてます。  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "\n",
    "\n",
    "emoji_list_datas_path = \"./datas//Emoji Sheets - Emoji Only.csv\"\n",
    "emoji_df = pd.read_csv(emoji_list_datas_path)\n",
    "\n",
    "# Extract the emojis into a list\n",
    "emoji_list = emoji_df[\"Emoji_List\"].tolist()\n",
    "\n",
    "# Start the pattern string\n",
    "pattern = \"[\"\n",
    "\n",
    "# Append each code point to the pattern string, ensuring each one is 8 digits\n",
    "for cp in emoji_list:\n",
    "    pattern += f\"\\\\U{cp[1:]:0>8}\"\n",
    "\n",
    "# Close the pattern string\n",
    "pattern += \"]\"\n",
    "\n",
    "# Compile the regular expression\n",
    "emoji_pattern = re.compile(pattern, re.UNICODE)\n",
    "\n",
    "\n",
    "# function to completely remove the emojis from the comments using re\n",
    "def remove_emojis(text):\n",
    "    if not isinstance(text, str):\n",
    "        return text  # or return an empty string: return ''\n",
    "\n",
    "    # Compile the regular expression\n",
    "    emoji_pattern = re.compile(pattern, re.UNICODE)\n",
    "\n",
    "    # Use the sub method to remove emojis\n",
    "    text_no_emojis = emoji_pattern.sub(r\"\", text)\n",
    "    return text_no_emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Removing emojis from English text: 100%|██████████| 201607/201607 [00:11<00:00, 18235.04it/s]\n",
      "Removing emojis from Japanese text: 100%|██████████| 201607/201607 [00:05<00:00, 39889.13it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "tqdm.pandas(desc=\"Removing emojis from English text\")\n",
    "df[\"english\"] = df[\"english\"].progress_apply(remove_emojis)\n",
    "\n",
    "tqdm.pandas(desc=\"Removing emojis from Japanese text\")\n",
    "df[\"japanese\"] = df[\"japanese\"].progress_apply(remove_emojis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mojimoji\n",
    "def zen_to_han(text):\n",
    "    return mojimoji.zen_to_han(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing accented characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('こんにちは。 今日は', 'Hello world e ')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import unicodedata\n",
    "\n",
    "# English might have accent like é but Japanese doesn't have any accent I just create different function to ascii for Japanese and English\n",
    "# Removing accented characters\n",
    "def english_unicode_to_ascii(text):\n",
    "    return \"\".join(\n",
    "        ascii_text\n",
    "        for ascii_text in unicodedata.normalize(\"NFKD\", text)\n",
    "        .encode(\"ascii\", \"ignore\")\n",
    "        .decode(\"utf-8\", \"ignore\")\n",
    "    )\n",
    "\n",
    "def japanese_unicode_to_ascii(text):\n",
    "    return \"\".join(ascii_text for ascii_text in unicodedata.normalize(\"NFKD\", text))\n",
    "\n",
    "\n",
    "japanese_unicode_to_ascii(\"こんにちは。 今日は\"), english_unicode_to_ascii(\n",
    "    \"Hello world é \"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove all punctuation and special characters, keeping only the specified characters (a-z, A-Z, Kanji, Katakana, Hiragana)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "こんにちは 世界 this is an example sentence\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    # Define regex pattern for allowed characters (Latin letters and Japanese characters)\n",
    "    allowed_pattern = r\"[^a-zA-Z\\u4E00-\\u9FFF\\u3040-\\u30FF\\s]\"\n",
    "    # Replace everything not in allowed pattern with a space\n",
    "    cleaned_text = re.sub(allowed_pattern, \" \", text)\n",
    "\n",
    "    # Remove extra spaces\n",
    "    cleaned_text = re.sub(r\"\\s+\", \" \", cleaned_text).strip()\n",
    "    \n",
    "    cleaned_text=cleaned_text.lower()\n",
    "\n",
    "    return cleaned_text\n",
    "\n",
    "# Example usage\n",
    "text = \"こんにちは、世界! This is an example sentence.\"\n",
    "print(clean_text(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "私 は 日本語 の ﾃｷｽﾄ を 翻訳 し ます ｡\n"
     ]
    }
   ],
   "source": [
    "from janome.tokenizer import Tokenizer\n",
    "import mojimoji\n",
    "\n",
    "# Initialize Japanese tokenizer\n",
    "tokenizer = Tokenizer()\n",
    "\n",
    "\n",
    "def preprocess_japanese_text(text):\n",
    "    # Convert full-width characters to half-width\n",
    "    text = mojimoji.zen_to_han(text)\n",
    "\n",
    "    # Tokenize the text\n",
    "    tokens = tokenizer.tokenize(text, wakati=True)\n",
    "\n",
    "    # Join tokens with a space to preserve word boundaries for translation models\n",
    "    preprocessed_text = \" \".join(tokens)\n",
    "\n",
    "    # Remove any unnecessary whitespace\n",
    "    preprocessed_text = preprocessed_text.strip()\n",
    "\n",
    "    return preprocessed_text\n",
    "\n",
    "\n",
    "text = \"私は日本語のテキストを翻訳します。\"\n",
    "processed_text = preprocess_japanese_text(text)\n",
    "print(processed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: 私, POS: 名詞,代名詞,一般,*\n",
      "Word: は, POS: 助詞,係助詞,*,*\n",
      "Word: 猫, POS: 名詞,一般,*,*\n",
      "Word: が, POS: 助詞,格助詞,一般,*\n",
      "Word: 好き, POS: 名詞,形容動詞語幹,*,*\n",
      "Word: です, POS: 助動詞,*,*,*\n",
      "Word: 。, POS: 記号,句点,*,*\n"
     ]
    }
   ],
   "source": [
    "# Sample Japanese sentence\n",
    "sentence = \"私は猫が好きです。\"\n",
    "\n",
    "# Tokenize and print POS information\n",
    "for token in tokenizer.tokenize(sentence):\n",
    "    print(f\"Word: {token.surface}, POS: {token.part_of_speech}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
